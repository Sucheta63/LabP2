import heapq
class node:
    def __init__(self, freq, symbol, left=None, right=None):
        # frequency of symbol
        self.freq = freq

        # symbol name (character)
        self.symbol = symbol

        # node left of current node
        self.left = left

        # node right of current node
        self.right = right

        # tree direction (0/1)
        self.huff = ''

    def __lt__(self, nxt):
        return self.freq < nxt.freq


# utility function to print huffman
# codes for all symbols in the newly
# created Huffman tree
def printNodes(node, val=''):
    # huffman code for current node
    newVal = val + str(node.huff)

    # if node is not an edge node
    # then traverse inside it
    if (node.left):
        printNodes(node.left, newVal)
    if (node.right):
        printNodes(node.right, newVal)

        # if node is edge node then
        # display its huffman code
    if (not node.left and not node.right):
        print(f"{node.symbol} -> {newVal}")


# characters for huffman tree
# chars = ['a', 'b', 'c', 'd', 'e', 'f']
chars = []
n = int(input("Enter number of characters:"))
for i in range(0, n):
    ele = input("Enter character:")

    chars.append(ele)

# frequency of characters
# freq = [ 5, 9, 12, 13, 16, 45]
freq = []
for i in range(0, n):
    fre = int(input("Enter frequency:"))
    freq.append(fre)

# list containing unused nodes
nodes = []

# converting characters and frequencies
# into huffman tree nodes
for x in range(len(chars)):
    heapq.heappush(nodes, node(freq[x], chars[x]))

while len(nodes) > 1:
    # sort all the nodes in ascending order
    # based on their frequency
    left = heapq.heappop(nodes)
    right = heapq.heappop(nodes)

    # assign directional value to these nodes
    left.huff = 0
    right.huff = 1

    # combine the 2 smallest nodes to create
    # new node as their parent
    newNode = node(left.freq + right.freq, left.symbol + right.symbol, left, right)

    heapq.heappush(nodes, newNode)

# Huffman Tree is ready!
printNodes(nodes[0])

#analysis 
time complexity is nlogn 
- greedy technique 
	- used for data compression 
	- reduce size of data 
	- cost of normal message = 20 characters , using ASCII we do =160 bits 
- huffman encoding - vaariable coding
	- give small size code for more frequency characters
	- follow optimal merge pattern 
	- all alphabet arrange in increasing order of frequency 
		- merge 2 smallest and make one node 
		- and so on 
		- we got optimal merge pattern tree 
	- using this tree we get codes - left side mark 0 and right side 1 
		- and for each alphabet follow path from root 
